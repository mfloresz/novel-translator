{
  "gemini": {
    "name": "Google Gemini",
    "type": "gemini",
    "base_url": "https://generativelanguage.googleapis.com/v1beta/models",
    "models": {
      "gemini-flash": {
        "name": "Gemini Flash",
        "endpoint": "gemini-flash-latest:generateContent",
        "temperature": 0.7,
        "thinking": false
      },
      "gemini-flash-lite": {
        "name": "Gemini Flash Lite",
        "endpoint": "gemini-flash-lite-latest:generateContent",
        "temperature": 0.7,
        "thinking": false
      }
    }
  },
  "hyperbolic": {
    "name": "Hyperbolic",
    "type": "openai",
    "base_url": "https://api.hyperbolic.xyz/v1/chat/completions",
    "models": {
      "gpt-oss-120b": {
        "name": "GPT OSS 120B",
        "endpoint": "openai/gpt-oss-120b",
        "temperature": 0.7,
        "max_tokens": 100000,
        "top_p": 0.95,
        "thinking": true
      },
      "gpt-oss-20b": {
        "name": "GPT OSS 20B",
        "endpoint": "openai/gpt-oss-20b",
        "temperature": 0.7,
        "max_tokens": 90000,
        "top_p": 0.85,
        "thinking": true
      },
        "gpt-oss-20b": {
        "name": "Qwen3 80B A3B",
        "endpoint": "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "temperature": 0.7,
        "max_tokens": 90000,
        "top_p": 0.85,
        "thinking": false
      }
    }
  },
  "chutes": {
    "name": "Chutes AI",
    "type": "openai",
    "base_url": "https://llm.chutes.ai/v1/chat/completions",
    "models": {
      "mistral-small-3.2": {
        "name": "Mistral Small 3.2",
        "endpoint": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
        "max_tokens": 40000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "qwen3-a22b-think": {
        "name": "Qwen3 235B A22B T",
        "endpoint": "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "max_tokens": 200000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": true
      },
        "gpt-oss-20b": {
        "name": "GPT OSS 20B",
        "endpoint": "openai/gpt-oss-20b",
        "max_tokens": 100000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "gpt-oss-120b": {
        "name": "GPT OSS 120B",
        "endpoint": "openai/gpt-oss-120b",
        "max_tokens": 100000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "deepseek-v3.2": {
        "name": "DeepSeek TNG Chimera",
        "endpoint": "tngtech/DeepSeek-TNG-R1T2-Chimera",
        "max_tokens": 60000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "mistral-nemo": {
        "name": "Mistral Nemo",
        "endpoint": "unsloth/Mistral-Nemo-Instruct-2407",
        "max_tokens": 40000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "mistral-small-3.1": {
        "name": "Mistral Small 3.1",
        "endpoint": "chutesai/Mistral-Small-3.1-24B-Instruct-2503",
        "max_tokens": 40000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      }
    }
  },
  "mistral": {
    "name": "Mistral",
    "type": "openai",
    "base_url": "https://api.mistral.ai/v1/chat/completions",
    "models": {
      "ministral-14b": {
        "name": "Ministral 14B",
        "endpoint": "ministral-14b-latest",
        "max_tokens": 128000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
      "mistral-small": {
        "name": "Mistral Small",
        "endpoint": "magistral-small-latest",
        "max_tokens": 128000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      }
    }
  },
    "openrouter": {
    "name": "OpenRouter",
    "type": "openai",
    "base_url": "https://openrouter.ai/api/v1/chat/completions",
    "models": {
      "grok-4.1-fast": {
        "name": "Grok 4.1 Fast",
        "endpoint": "x-ai/grok-4.1-fast",
        "temperature": 0.7,
        "thinking": false,
        "include_reasoning": true,
        "reasoning": false
      }
    }
  }
}
