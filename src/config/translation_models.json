{
  "gemini": {
    "name": "Google Gemini",
    "type": "gemini",
    "base_url": "https://generativelanguage.googleapis.com/v1beta/models",
    "models": {
      "gemini-flash-lite": {
        "name": "Gemini Flash Lite",
        "endpoint": "gemini-flash-lite-latest:generateContent",
        "temperature": 0.6,
        "thinking": false
      }
    }
  },
  "hyperbolic": {
    "name": "Hyperbolic",
    "type": "openai",
    "base_url": "https://api.hyperbolic.xyz/v1/chat/completions",
    "models": {
      "gpt-oss-120b": {
        "name": "GPT OSS 120B",
        "endpoint": "openai/gpt-oss-120b",
        "temperature": 0.7,
        "max_tokens": 100000,
        "top_p": 0.95,
        "thinking": true
      },
      "qwen3-next-thinking": {
        "name": "Qwen3 80B A3B Tkinking",
        "endpoint": "Qwen/Qwen3-Next-80B-A3B-Thinking",
        "temperature": 0.7,
        "max_tokens": 200000,
        "top_p": 0.85,
        "thinking": true
      }
    }
  },
  "chutes": {
    "name": "Chutes AI",
    "type": "openai",
    "base_url": "https://llm.chutes.ai/v1/chat/completions",
    "models": {
      "mistral-3.2": {
        "name": "Mistral Small 3.2",
        "endpoint": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
        "max_tokens": 40000,
        "temperature": 0.6,
        "top_p": 0.95,
        "thinking": false
      },
        "qwen3-a22b-think": {
        "name": "Qwen3 235B A22B T",
        "endpoint": "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "max_tokens": 200000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": true
      },
        "gpt-oss-20b": {
        "name": "GPT OSS 20B",
        "endpoint": "openai/gpt-oss-20b",
        "max_tokens": 100000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "gpt-oss-120b": {
        "name": "GPT OSS 120B",
        "endpoint": "openai/gpt-oss-120b",
        "max_tokens": 100000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "qwen3-next-t": {
        "name": "Qwen3 80B A3B",
        "endpoint": "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "max_tokens": 256000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      },
        "long-cat-t": {
        "name": "LongCat Flash",
        "endpoint": "meituan-longcat/LongCat-Flash-Thinking-FP8",
        "max_tokens": 128000,
        "temperature": 0.7,
        "top_p": 0.95,
        "thinking": false
      }
    }
  },
  "mistral": {
    "name": "Mistral",
    "type": "openai",
    "base_url": "https://api.mistral.ai/v1/chat/completions",
    "models": {
      "magistral-small": {
        "name": "Magistral Small",
        "endpoint": "magistral-small-latest",
        "max_tokens": 128000,
        "temperature": 0.6,
        "top_p": 0.95,
        "thinking": true
      }
    }
  }
}
